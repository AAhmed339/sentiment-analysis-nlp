{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb0dba4-2feb-4187-a068-9811fcde3689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\AhmedCoding'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c921f2-4ac6-4b51-86f8-a0c650f1249d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 تشغيل المكتبات\n",
    "\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ثبات النتائج (اختياري)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb00c22-225d-446e-b6a0-671c93f4d44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,\n",
       " 3,\n",
       " [('this film is terrible', 0), ('this is wonderful', 1)],\n",
       " [('i love this movie', 1), ('this film is amazing', 1)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) تجهيز بيانات تدريب صغيرة (للتعلم)\n",
    "\n",
    "\n",
    "data = [\n",
    "    (\"i love this movie\", 1),\n",
    "    (\"this film is amazing\", 1),\n",
    "    (\"what a great experience\", 1),\n",
    "    (\"i enjoyed the story\", 1),\n",
    "    (\"fantastic acting and plot\", 1),\n",
    "    (\"this is wonderful\", 1),\n",
    "\n",
    "    (\"i hate this movie\", 0),\n",
    "    (\"this film is terrible\", 0),\n",
    "    (\"what a bad experience\", 0),\n",
    "    (\"i disliked the story\", 0),\n",
    "    (\"awful acting and plot\", 0),\n",
    "    (\"this is horrible\", 0),\n",
    "]\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "split = int(0.8 * len(data))\n",
    "train_data = data[:split]\n",
    "val_data = data[split:]\n",
    "\n",
    "len(train_data), len(val_data), train_data[:2], val_data[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd86efa-3081-4c4a-b79c-2794436f2fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fantastic', 'acting', 'and', 'plot']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Tokenization (تقطيع النص)\n",
    "# نكتب Tokenizer بسيط:\n",
    "# نحول لحروف صغيرة\n",
    "# نشيل الرموز\n",
    "# نقسم بكلمات\n",
    "\n",
    "\n",
    "def tokenize(text: str):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "tokenize(\"Fantastic acting!!! and plot.\")  # اختبار\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6779f50e-1a7d-4c30-85fc-76ab8d958d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,\n",
       " [('<PAD>', 0),\n",
       "  ('<UNK>', 1),\n",
       "  ('a', 2),\n",
       "  ('acting', 3),\n",
       "  ('and', 4),\n",
       "  ('bad', 5),\n",
       "  ('disliked', 6),\n",
       "  ('enjoyed', 7),\n",
       "  ('experience', 8),\n",
       "  ('fantastic', 9)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# بناء Vocabulary + كلمات خاصة\n",
    "# نحتاج كلمات خاصة:\n",
    "# <PAD> للحشو\n",
    "# <UNK> للكلمات غير المعروفة\n",
    "\n",
    "\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "def build_vocab(dataset, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for text, _ in dataset:\n",
    "        counter.update(tokenize(text))\n",
    "    words = [w for w, c in counter.items() if c >= min_freq]\n",
    "    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "    for w in sorted(words):\n",
    "        if w not in vocab:\n",
    "            vocab[w] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(train_data, min_freq=1)\n",
    "vocab_size = len(vocab)\n",
    "vocab_size, list(vocab.items())[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e66e9b-69c0-4da0-87c9-279d4db4fb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([14, 1, 21, 1, 10], [14, 1, 21, 1, 10, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Encoding + Padding + Truncation\n",
    "\n",
    "# Encoding: كل كلمة تتحول إلى رقم\n",
    "\n",
    "# Padding: نخلي كل الجمل نفس الطول max_len\n",
    "\n",
    "# Truncation: نقص الجمل الطويلة\n",
    "\n",
    "\n",
    "def encode(tokens, vocab):\n",
    "    return [vocab.get(t, vocab[UNK_TOKEN]) for t in tokens]\n",
    "\n",
    "def pad_sequence(ids, max_len, pad_id=0):\n",
    "    if len(ids) < max_len:\n",
    "        return ids + [pad_id] * (max_len - len(ids))\n",
    "    return ids[:max_len]\n",
    "\n",
    "MAX_LEN = 6  # للتبسيط\n",
    "\n",
    "# مثال\n",
    "example = \"i love this amazing film\"\n",
    "ids = encode(tokenize(example), vocab)\n",
    "ids, pad_sequence(ids, MAX_LEN, vocab[PAD_TOKEN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f253b1d4-75b9-4017-9e4e-747f6866fdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 6]), tensor([1, 0, 1, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset و DataLoader\n",
    "# سنُرجع:\n",
    "# input_ids: شكلها [max_len]\n",
    "# label: 0/1\n",
    "\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_len):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        self.pad_id = vocab[PAD_TOKEN]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, label = self.data[idx]\n",
    "        tokens = tokenize(text)\n",
    "        ids = encode(tokens, self.vocab)\n",
    "        ids = pad_sequence(ids, self.max_len, self.pad_id)\n",
    "        return torch.tensor(ids, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_ds = TextDataset(train_data, vocab, MAX_LEN)\n",
    "val_ds = TextDataset(val_data, vocab, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "batch[0].shape, batch[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ccd066-dff2-464f-9bf5-da604f841419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSentiment(\n",
       "  (embedding): Embedding(24, 64, padding_idx=0)\n",
       "  (lstm): LSTM(64, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9) بناء نموذج LSTM للتصنيف\n",
    "# الفكرة:\n",
    "\n",
    "# Embedding → LSTM → نأخذ آخر تمثيل (أو hidden state) → Linear → logits\n",
    "\n",
    "# ثم CrossEntropyLoss\n",
    "\n",
    "\n",
    "\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, hidden_dim=64, num_layers=1, pad_idx=0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 2)  # 2 classes: negative/positive\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # input_ids: [B, T]\n",
    "        x = self.embedding(input_ids)      # [B, T, E]\n",
    "        out, (h, c) = self.lstm(x)         # h: [num_layers, B, H]\n",
    "        last_h = h[-1]                     # [B, H]\n",
    "        logits = self.fc(last_h)           # [B, 2]\n",
    "        return logits\n",
    "\n",
    "model = LSTMSentiment(vocab_size=vocab_size, embed_dim=64, hidden_dim=64, pad_idx=vocab[PAD_TOKEN]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259c399c-3441-4f9c-8523-998c2b09f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) التدريب خطوة بخطوة\n",
    "# 10.1 دوال مساعدة: Accuracy + تمريرة Epoch\n",
    "\n",
    "\n",
    "def accuracy_from_logits(logits, y):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == y).float().mean().item()\n",
    "\n",
    "def run_epoch(model, loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for input_ids, labels in loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(input_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "            acc = accuracy_from_logits(logits, labels)\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / n_batches, total_acc / n_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "809b6a44-576b-4616-a70a-da45a79591d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train loss 0.7025 acc 0.333 | Val loss 0.6989 acc 0.333\n",
      "Epoch 05 | Train loss 0.6609 acc 0.833 | Val loss 0.7492 acc 0.000\n",
      "Epoch 10 | Train loss 0.5931 acc 0.750 | Val loss 0.9007 acc 0.000\n",
      "Epoch 15 | Train loss 0.4018 acc 0.917 | Val loss 1.2979 acc 0.000\n",
      "Epoch 20 | Train loss 0.1580 acc 1.000 | Val loss 2.1850 acc 0.000\n"
     ]
    }
   ],
   "source": [
    "# 10.2 تدريب عدة Epochs/\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = run_epoch(model, train_loader, train=True)\n",
    "    val_loss, val_acc = run_epoch(model, val_loader, train=False)\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:02d} | \"\n",
    "              f\"Train loss {train_loss:.4f} acc {train_acc:.3f} | \"\n",
    "              f\"Val loss {val_loss:.4f} acc {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72e5506-64ad-4d27-918d-4fb9069a70f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love this film          -> NEGATIVE | probs=[0.87378013 0.1262199 ]\n",
      "this movie is horrible    -> NEGATIVE | probs=[0.9786391  0.02136091]\n",
      "great acting              -> POSITIVE | probs=[0.22850707 0.77149296]\n",
      "bad plot                  -> POSITIVE | probs=[0.30520442 0.6947956 ]\n",
      "i enjoyed this            -> POSITIVE | probs=[0.47996175 0.5200383 ]\n",
      "awful movie               -> NEGATIVE | probs=[0.8067603  0.19323973]\n"
     ]
    }
   ],
   "source": [
    "# 11) تجربة النموذج على جمل جديدة (Inference)\n",
    "\n",
    "# سنكتب دالة:\n",
    "# tokenize → encode → pad → model → softmax → قرار\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_sentiment(text: str):\n",
    "    model.eval()\n",
    "    tokens = tokenize(text)\n",
    "    ids = encode(tokens, vocab)\n",
    "    ids = pad_sequence(ids, MAX_LEN, vocab[PAD_TOKEN])\n",
    "    x = torch.tensor([ids], dtype=torch.long).to(device)  # [1, T]\n",
    "    logits = model(x)\n",
    "    probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    pred = int(probs.argmax())\n",
    "    label = \"POSITIVE\" if pred == 1 else \"NEGATIVE\"\n",
    "    return label, probs\n",
    "\n",
    "tests = [\n",
    "    \"i love this film\",\n",
    "    \"this movie is horrible\",\n",
    "    \"great acting\",\n",
    "    \"bad plot\",\n",
    "    \"i enjoyed this\",\n",
    "    \"awful movie\"\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    label, probs = predict_sentiment(t)\n",
    "    print(f\"{t:25s} -> {label} | probs={probs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9362ecf9-93c6-4c22-b692-ed0b97e68cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lstm_sentiment.pt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12) حفظ النموذج (اختياري لكنه مهم للبورتفوليو)\n",
    "\n",
    "\n",
    "\n",
    "save_path = \"lstm_sentiment.pt\"\n",
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"vocab\": vocab,\n",
    "    \"max_len\": MAX_LEN\n",
    "}, save_path)\n",
    "\n",
    "save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea8579-8340-42a3-ad86-f846c31f695b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
